


<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<meta property="og:title" content="Two-Dimensional Example" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://ameli.github.io/tutorials/two_dimensional_example.html" />
<meta property="og:site_name" content="g-learn" />
<meta property="og:description" content="This is a quick tutorial to demonstrate basic usage of the G-Learn package. Import: Import the package using: Before starting, you can check the version of G-Learn, the available number of CPU processors, GPU devices, and memory usage of the current Python process via: Generate Points: We generat..." />
<meta property="og:image" content="https://raw.githubusercontent.com/ameli/glearn/main/docs/source/_static/images/icons/logo-glearn-light.svg" />
<meta property="og:image:alt" content="g-learn" />
<meta name="description" content="This is a quick tutorial to demonstrate basic usage of the G-Learn package. Import: Import the package using: Before starting, you can check the version of G-Learn, the available number of CPU processors, GPU devices, and memory usage of the current Python process via: Generate Points: We generat..." />
<meta property="og:title" content="RestoreIO">
<meta property="og:description" content="g-learn is a modular and high-performance Python package for machine learning using Gaussian process regression with novel algorithms capable of petascale computation on multi-GPU devices.">

    <title>Two-Dimensional Example &#8212; glearn Manual</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom-pydata.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/toggleprompt.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom-pydata.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/custom-pydata.css"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quick Start" href="quick_start.html" />
    <link rel="prev" title="Tutorials" href="tutorials.html" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RCTBMM27GH"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-RCTBMM27GH');
    </script>

    <script defer data-domain="docs.scipy.org" src="https://views.scientific-python.org/js/script.js"></script>

    <!-- My custom JS -->
    <script type="text/javascript" src="../_static/js/custom-pydata.js"></script>

    <!-- Syntax highlighting for BibTex code blocks -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-solarizedlight.min.css"/>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js"></script>

    
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../contents.html">
  
  
  
  
    <img src="../_static/images/icons/logo-glearn-light.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/images/icons/logo-glearn-dark.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../install/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../docker/docker.html">
  Docker
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gpu/gpu.html">
  GPU
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="tutorials.html">
  Tutorials
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ameli/glearn" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://pypi.org/project/glearn/" rel="noopener" target="_blank" title="PyPI"><span><i class="fab fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://anaconda.org/s-ameli/glearn" rel="noopener" target="_blank" title="Anaconda Cloud"><span><i class="fa fa-circle-notch"></i></span>
            <label class="sr-only">Anaconda Cloud</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://hub.docker.com/r/sameli/glearn" rel="noopener" target="_blank" title="Docker Hub"><span><i class="fab fa-docker"></i></span>
            <label class="sr-only">Docker Hub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mybinder.org/v2/gh/ameli/glearn/HEAD?filepath=notebooks%2FInterpolateTraceOfInverse.ipynb" rel="noopener" target="_blank" title="Lanuch Jupyter on Binder"><span><i class="fas fa-book-open"></i></span>
            <label class="sr-only">Lanuch Jupyter on Binder</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   2D Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="quick_start.html">
   Quick Start
  </a>
 </li>
</ul>

    
  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Import">
   Import
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Generate-Points">
   Generate Points
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Generate-Noisy-Data">
   Generate Noisy Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Stochastic-Model-for-Noisy-Data">
   Stochastic Model for Noisy Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Design-Matrix">
   Design Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Prior-for-Parameter-\boldsymbol{\beta}">
   Prior for Parameter
   <span class="math notranslate nohighlight">
    \(\boldsymbol{\beta}\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Linear-Model">
   Linear Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Kernels">
   Kernels
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Scale-Hyperparameter">
   Scale Hyperparameter
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Covariance">
   Covariance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Gaussian-Process">
   Gaussian Process
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Training-Hyperparameters">
   Training Hyperparameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Prediction">
   Prediction
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      

<div class="tocsection editthispage">
    <a href="https://github.com/ameli/glearn/edit/main/docs/source/tutorials/two_dimensional_example.ipynb">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="Two-Dimensional-Example">
<h1>Two-Dimensional Example<a class="headerlink" href="#Two-Dimensional-Example" title="Permalink to this heading">#</a></h1>
<p>This is a quick tutorial to demonstrate basic usage of the G-Learn package.</p>
<section id="Import">
<h2>Import<a class="headerlink" href="#Import" title="Permalink to this heading">#</a></h2>
<p>Import the package using:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import glearn
</pre></div>
</div>
</div>
<p>Before starting, you can check the version of G-Learn, the available number of CPU processors, GPU devices, and memory usage of the current Python process via:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>glearn.info()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

glearn version  : 0.21.1
imate version   : 0.18.0
processor       : Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz
num threads     : 4
gpu device      : not found
num gpu devices : 0
cuda version    : not found
nvidia driver   : not found
process memory  : 124.2 (Mb)

</pre></div></div>
</div>
</section>
<section id="Generate-Points">
<h2>Generate Points<a class="headerlink" href="#Generate-Points" title="Permalink to this heading">#</a></h2>
<p>We generate a set of 50 points randomly distributed in the domain <span class="math notranslate nohighlight">\(\mathcal{D} = [0, 1]^2\)</span>, where <span class="math notranslate nohighlight">\(80\%\)</span> more points are concentrated in the sub-domain <span class="math notranslate nohighlight">\([a=0.4, b=0.6]^2\)</span> with a uniform distribution, and the rest of the points are spread uniformly elsewhere.</p>
<p>For simplicity, you can create such a set of points using the <code class="docutils literal notranslate"><span class="pre">glearn.sample_data</span></code> module.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from glearn import sample_data
x = sample_data.generate_points(num_points=100, dimension=2,
                                grid=False,a=[0.4, 0.4], b=[0.6, 0.6],
                                contrast=0.9, seed=42)
</pre></div>
</div>
</div>
</section>
<section id="Generate-Noisy-Data">
<h2>Generate Noisy Data<a class="headerlink" href="#Generate-Noisy-Data" title="Permalink to this heading">#</a></h2>
<p>On the set of points <span class="math notranslate nohighlight">\(\boldsymbol{x} = (x_1, \dots, x_d) \in \mathcal{D} \in \mathbb{R}^d\)</span> (where <span class="math notranslate nohighlight">\(d=1\)</span> as specified above), we define a stochastic function:</p>
<div class="math notranslate nohighlight">
\[y(\boldsymbol{x}) = \sum_{i=1}^d \sin\left(\pi x_i \right) + \epsilon,\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon\)</span> is a random variable <span class="math notranslate nohighlight">\(\epsilon(x) \sim \mathcal{N}(0, \sigma_0^2)\)</span> with a noise standard deviation of <span class="math notranslate nohighlight">\(\sigma_0 = 0.05\)</span>.</p>
<p>You can generate the random data described above using the <code class="docutils literal notranslate"><span class="pre">glearn.sample_data</span></code> module.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_noisy = sample_data.generate_data(x, noise_magnitude=0.1, plot=True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_two_dimensional_example_7_0.png" src="../_images/tutorials_two_dimensional_example_7_0.png" />
</div>
</div>
<p>The figure above illustrates the noisy data (represented as dots) alongside the original function without noise (depicted as a solid curve). It’s important to note that the majority of data points are concentrated within the sub-domain <span class="math notranslate nohighlight">\([0.4, 0.6]^2\)</span>, while outside this interval, data points are sparsely distributed.</p>
<p>Later on, we will demonstrate accurate predictions within the concentrated sub-interval and less precise predictions outside of it.</p>
</section>
<section id="Stochastic-Model-for-Noisy-Data">
<h2>Stochastic Model for Noisy Data<a class="headerlink" href="#Stochastic-Model-for-Noisy-Data" title="Permalink to this heading">#</a></h2>
<p>We model the random data <span class="math notranslate nohighlight">\(z\)</span> as:</p>
<div class="math notranslate nohighlight">
\[y(x) = \mu(x) + \delta(x) + \epsilon(x),\]</div>
<p>where:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mu(x)\)</span> represents a deterministic mean function.</p></li>
<li><p><span class="math notranslate nohighlight">\(\delta(x)\)</span> is a zero-mean stochastic function that will be determined later.</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon(x)\)</span> is a zero-mean stochastic function representing the input noise and characterized by the discrete covariance:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\epsilon(x), \epsilon(x')] = \sigma_0^2 \mathbf{I}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> is the identity matrix, and the hyperparameter <span class="math notranslate nohighlight">\(\sigma_0^2\)</span> is the variance of the noise. It is assumed that the noise variance is not known.</p>
</li>
</ul>
</section>
<section id="Design-Matrix">
<h2>Design Matrix<a class="headerlink" href="#Design-Matrix" title="Permalink to this heading">#</a></h2>
<p>We represent the deterministic mean function <span class="math notranslate nohighlight">\(\mu\)</span> using the linear model <span class="math notranslate nohighlight">\(\mu(\boldsymbol{x}) = \boldsymbol{\phi}(x)^{\intercal} \boldsymbol{\beta}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\phi}(x): \mathcal{D} \to \mathbb{R}^m\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\beta} \in \mathbb{R}^{m}\)</span> are the parameters. On discrete points <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, the set of basis functions is discretized into the design matrix <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{n \times m}\)</span>:</p>
<div class="math notranslate nohighlight">
\[X_{ij} = \phi_{j}(\boldsymbol{x}_i)\]</div>
<p>Other ways to construct the design matrix include using trigonometric functions, hyperbolic functions, user-defined custom functions, or a combination of all. In this case, only a fifth-order monomial is used:</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{\phi}(\boldsymbol{x}) = (1, x, \cdots, x^4)^{\intercal}.\]</div>
<p>Hence, in this context, <span class="math notranslate nohighlight">\(m = 5\)</span>.</p>
</section>
<section id="Prior-for-Parameter-\boldsymbol{\beta}">
<h2>Prior for Parameter <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span><a class="headerlink" href="#Prior-for-Parameter-\boldsymbol{\beta}" title="Permalink to this heading">#</a></h2>
<p>A normal prior is prescribed for the unknown parameter <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[p(\boldsymbol{\beta} | \sigma^2) \sim \mathcal{N}(\boldsymbol{b}, \sigma^2 \mathbf{B}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^2 \mathbf{B} \in \mathbb{R}^{m \times m}\)</span> represents the covariance of <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>. The hyperparameter <span class="math notranslate nohighlight">\(\sigma^2\)</span> denotes the variance of the regression and is not known.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Mean of hyperparameter beta.
# The size of b should be m, the number of columns of design matrix X.
import numpy
b = numpy.zeros((21, ))

# Generate a random matrix B for covariance of beta.
# The shape of matrix B should be (m, m)
numpy.random.seed(0)
B = numpy.random.rand(b.size, b.size)

# Making sure the covariance matrix B positive-semidefinite
B = 1e+5 * B.T @ B
</pre></div>
</div>
</div>
</section>
<section id="Linear-Model">
<h2>Linear Model<a class="headerlink" href="#Linear-Model" title="Permalink to this heading">#</a></h2>
<p>The linear model with mean <span class="math notranslate nohighlight">\(\mu = \mathbf{X} \boldsymbol{\beta}\)</span> can be created using the <code class="docutils literal notranslate"><span class="pre">glearn.mean.LinearModel</span></code> class:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Create mean object using glearn.
mean = glearn.LinearModel(x, polynomial_degree=5, b=b, B=B)
</pre></div>
</div>
</div>
</section>
<section id="Kernels">
<h2>Kernels<a class="headerlink" href="#Kernels" title="Permalink to this heading">#</a></h2>
<p>The zero-mean stochastic function <span class="math notranslate nohighlight">\(\delta(x): \mathcal{D} \to \mathbb{R}\)</span> is characterized by its covariance,</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\delta(x), \delta(x')] = k(x, x'|\boldsymbol{\alpha}).\]</div>
<p>The function <span class="math notranslate nohighlight">\(k: \mathcal{D} \times \mathcal{D} \times \mathbb{R}^d \to \mathbb{R}\)</span> represents the correlation kernel and can be created using the <code class="docutils literal notranslate"><span class="pre">glearn.kernel</span></code> module. Various kernels available in this module include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Matern()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Exponential()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SquareExponential()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RationalQuadratic()</span></code></p></li>
</ul>
<p>In this example, we use the exponential kernel.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from glearn import kernels
kernel = kernels.Exponential()
kernel.plot()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_two_dimensional_example_15_0.png" src="../_images/tutorials_two_dimensional_example_15_0.png" />
</div>
</div>
</section>
<section id="Scale-Hyperparameter">
<h2>Scale Hyperparameter<a class="headerlink" href="#Scale-Hyperparameter" title="Permalink to this heading">#</a></h2>
<p>The hyperparameters <span class="math notranslate nohighlight">\(\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_d) \in \mathbb{R}^d\)</span> determines the scale of each spatial dimension. In our example, <span class="math notranslate nohighlight">\(d=1\)</span>. Scale can be either explicitly given if known, or can be characterized by a prior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\alpha})\)</span> using <code class="docutils literal notranslate"><span class="pre">glearn.priors</span></code> class. A list of available priors are</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Uniform</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Cauchy</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">StudentT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">InverseGamma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Normal</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Erlang</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BetaPrime</span></code></p></li>
</ul>
<p>Here, we use Cauchy prior. We also plot the prior and its frist and second derivative.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from glearn import priors
scale = priors.Cauchy()
scale.plot()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_two_dimensional_example_17_0.png" src="../_images/tutorials_two_dimensional_example_17_0.png" />
</div>
</div>
</section>
<section id="Covariance">
<h2>Covariance<a class="headerlink" href="#Covariance" title="Permalink to this heading">#</a></h2>
<p>The covariance of the model is given by:</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{\Sigma}(\sigma^2, \sigma_0^2, \boldsymbol{\alpha}) = \sigma^2 \mathbf{K}(\boldsymbol{\alpha}) + \sigma_0^2 \mathbf{I},\]</div>
<p>where:</p>
<div class="math notranslate nohighlight">
\[\mathbf{K}(\boldsymbol{\alpha}): \mathbb{R}^{d} \to \mathbb{R}^{n \times n},\]</div>
<p>and <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> represents the identity matrix.</p>
<p>An object of the above covariance model can be created using the <code class="docutils literal notranslate"><span class="pre">glearn.Covariance</span></code> class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cov = glearn.Covariance(x, kernel=kernel, scale=scale)
</pre></div>
</div>
</div>
</section>
<section id="Gaussian-Process">
<h2>Gaussian Process<a class="headerlink" href="#Gaussian-Process" title="Permalink to this heading">#</a></h2>
<p>The Gaussian process is defined as:</p>
<div class="math notranslate nohighlight">
\[z \sim \mathcal{GP}(\mu, \boldsymbol{\Sigma})\]</div>
<p>You can create the Gaussian process using the <code class="docutils literal notranslate"><span class="pre">glearn.GaussianProcess</span></code> class, which utilizes the mean and covariance objects.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>gp = glearn.GaussianProcess(mean, cov)
</pre></div>
</div>
</div>
</section>
<section id="Training-Hyperparameters">
<h2>Training Hyperparameters<a class="headerlink" href="#Training-Hyperparameters" title="Permalink to this heading">#</a></h2>
<p>The hyperparameters <span class="math notranslate nohighlight">\((\sigma, \sigma_0, \boldsymbol{\alpha})\)</span> and the parameter <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> can be trained using the <code class="docutils literal notranslate"><span class="pre">gp.train()</span></code> function.</p>
<p>The type of profiling for the likelihood function can be set using the <code class="docutils literal notranslate"><span class="pre">profile_hyperparam</span></code> argument, which can take one of the following values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no profiling</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'var'</span></code>: profiling on variance hyperparameter.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'var_noise'</span></code>: profiling on both variance and noise hyperparameters.</p></li>
</ul>
<p>The optimization method can be set using the <code class="docutils literal notranslate"><span class="pre">optimization_method</span></code> argument, which can be one of the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'chandrupatla'</span></code>: requires Jacobian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'brentq'</span></code>: requires Jacobian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Nelder-Mead'</span></code>: requires function</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'BFGS'</span></code>: requires function, Jacobian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'CG'</span></code>: requires function, Jacobian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Newton-CG'</span></code>: requires function, Jacobian, Hessian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dogleg'</span></code>: requires function, Jacobian, Hessian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'trust-exact'</span></code>: requires function, Jacobian, Hessian</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'trust-ncg'</span></code>: requires function, Jacobian, Hessian</p></li>
</ul>
<p>The internal matrix algebra of this object can be set using the <code class="docutils literal notranslate"><span class="pre">imate_method</span></code> argument, which can take one of the following values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">eigenvalue</span></code>: using the eigenvalue method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cholesky</span></code>: using the Cholesky method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hutchinson</span></code>: using the stochastic Hutchinson method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slq</span></code>: using the stochastic Lanczos quadrature method.</p></li>
</ul>
<p>In this example, we use the Cholesky method.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>profile_hyperparam = &#39;var&#39;
optimization_method = &#39;Newton-CG&#39;
imate_options = {&#39;method&#39;: &#39;cholesky&#39;}
hyperparam_guess = None
result = gp.train(y_noisy, profile_hyperparam=profile_hyperparam,
                  log_hyperparam=True, hyperparam_guess=hyperparam_guess,
                  optimization_method=optimization_method, tol=1e-6,
                  max_iter=1000, use_rel_error=True, imate_options=imate_options,
                  verbose=True, plot=False)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

               Error
====================================
itr   param  1   param  2   param  3
---   --------   --------   --------
001        inf        inf        inf
002   1.64e-01   4.29e-01   4.18e-01
003   3.28e-02   6.81e-01   6.70e-01
004   2.01e-03   3.56e-01   3.74e-01
005   1.29e-03   2.33e-01   2.89e-01
006   7.18e-04   1.28e-01   2.99e-01
007   2.28e-05   1.07e-02   7.00e-02
008   2.88e-05   1.60e-03   3.86e-03
009   2.26e-07   1.19e-04   1.30e-05
010   1.65e-07   1.01e-07   3.89e-10

                                Training Summary
================================================================================
       posterior/param                optimization              imate solver
-----------------------------      -------------------      --------------------
posterior    +5.892157773e+01      method    Newton-CG      method      cholesky
eta          4.6442467478e+02      tol        1.00e-06      tol         1.00e-08
sigma        4.8346786357e-03      max iter       1000      interpolate    False
sigma0       1.0418981199e-01      max bracket try   6      min num samples    0
alpha        6.55e-2, 2.72e-2      profile param   var      max num samples    0

                                    Process
================================================================================
         time (sec)                    evaluations               processor
-----------------------------      -------------------      --------------------
task         clock    process      task              #      device             #
================================================================================
correlation  7.47e-1  2.75e+0      correlation      32      cpu threads        4
logdet       1.42e-2  5.31e-2      likelihood       24      gpu devices        0
traceinv     9.54e-1  3.44e+0      jacobian         24      gpu multiproc      0
solver       4.40e-1  1.61e+0      hessian          10      gpu thrds/sm       0
overall      2.81e+0  1.03e+1      optimization     10      mem used (b) 2260992

</pre></div></div>
</div>
</section>
<section id="Prediction">
<h2>Prediction<a class="headerlink" href="#Prediction" title="Permalink to this heading">#</a></h2>
<p>After training the hyperparameters, the <code class="docutils literal notranslate"><span class="pre">gp</span></code> object is ready to predict the data on new points. First, we create a set of <span class="math notranslate nohighlight">\(50^2\)</span> test points <span class="math notranslate nohighlight">\(x^{\star}\)</span> equally spaced in the domain <span class="math notranslate nohighlight">\([0, 1]^2\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Generate test points
test_points = sample_data.generate_points(num_points=50, dimension=2, grid=True)
</pre></div>
</div>
</div>
<p>Note that the above step is unnecessary and is only used for the purpose of comparison with the prediction since we already know the exact function that generated the noisy data <span class="math notranslate nohighlight">\(z\)</span> in the first place.</p>
<p>The posterior predictive distribution of the prediction <span class="math notranslate nohighlight">\(z^{\star}(x^{\star})\)</span> takes the form:</p>
<div class="math notranslate nohighlight">
\[z^{\star}(x^{\star}) \sim \mathcal{N}\left(\mu^{\star}(x^{\star}), \mathbf{\Sigma}^{\star \star}(x^{\star}, x'^{\star})\right)\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu^{\star}\)</span> is the posterior predictive mean, and</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{\star \star}\)</span> is the posterior predictive covariance between test points and themselves.</p></li>
</ul>
<p>Prediction can be made using the <code class="docutils literal notranslate"><span class="pre">gp.predict()</span></code> function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>z_star_mean, z_star_cov = gp.predict(test_points, cov=True, plot=True,
                                     confidence_level=0.95, verbose=True)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

                               Prediction Summary
================================================================================
               process                                    config
-------------------------------------      -------------------------------------
wall time (sec)               7.15e-1      num training points               100
proc time (sec)               1.95e+0      num test points                  2500
memory used (b)              66920448      compute covariance               True

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_two_dimensional_example_27_1.png" src="../_images/tutorials_two_dimensional_example_27_1.png" />
</div>
</div>
<p>By setting the boolean argument <code class="docutils literal notranslate"><span class="pre">cov=False</span></code>, the predictive covariance is not computed, which enhances computational speed.</p>
<ul class="simple">
<li><p>When <code class="docutils literal notranslate"><span class="pre">cov=True</span></code>, meaning that both <span class="math notranslate nohighlight">\(\mu^{\star}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{\star \star}\)</span> are computed, the prediction process is <span class="math notranslate nohighlight">\(\mathcal{O}\left((n^{\star})^3\right)\)</span> complex.</p></li>
<li><p>In contrast, when <code class="docutils literal notranslate"><span class="pre">cov=False</span></code> to only compute <span class="math notranslate nohighlight">\(\mu^{\star}\)</span>, the prediction process is only <span class="math notranslate nohighlight">\(\mathcal{O}\left((n^{\star})^2\right)\)</span> complex.</p></li>
</ul>
<p>Furthermore, when <code class="docutils literal notranslate"><span class="pre">cov=False</span></code>, once the first prediction on a set of test points <span class="math notranslate nohighlight">\(\left\{ x_i^{\star} \right\}_{n^{\star}}\)</span> is made, the future calls to the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function are of order <span class="math notranslate nohighlight">\(\mathcal{O}(n^{\star})\)</span>, even when applied to a different set of test points. This is because the <code class="docutils literal notranslate"><span class="pre">gp</span></code> object stores all internal computations that are independent of the test points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>z_star_mean = gp.predict(test_points, cov=False, verbose=True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

                               Prediction Summary
================================================================================
               process                                    config
-------------------------------------      -------------------------------------
wall time (sec)               4.47e-2      num training points               100
proc time (sec)               1.10e-1      num test points                  2500
memory used (b)                     0      compute covariance              False

</pre></div></div>
</div>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="tutorials.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Tutorials</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="quick_start.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Quick Start</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>


    <!-- Adobe Embed API -->
    
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>


  </body>
</html>